# Analytics Engineer Test: Yelp Review & Weather Analysis

## Objective

This project aims to fulfill the requirements of the Analytics Engineer test. The primary goal was to design and build a Data Warehouse (DW) to analyze the potential impact of weather conditions (temperature, precipitation) on customer ratings for restaurants, using data provided from Yelp and the Global Historical Climatology Network-Daily (GHCN-D).

The project demonstrates:
*   Data Warehouse schema design (Star Schema).
*   ETL (Extract, Transform, Load) pipeline development using Python (Pandas, SQLAlchemy).
*   Data cleaning, transformation, and loading into an SQLite database.
*   SQL querying against the DW for analytical insights.

## Data Sources

*   **Yelp Academic Dataset:** Provided JSON files containing business, review, and user data.
    *   `yelp_academic_dataset_business.json`
    *   `yelp_academic_dataset_review.json`
    *   `yelp_academic_dataset_user.json` (Note: User dimension primarily built from review data in this implementation)
*   **GHCN-D Weather Data:** Provided CSV files containing daily weather observations (temperature, precipitation) for Las Vegas, NV.
    *   `temperature-degreef.csv`
    *   `las-vegas-mccarran-intl-ap-precipitation-inch.csv`

## Project Structure

├── data/ # Directory to store input data (Not submitted)
│ ├── Climate Data/ # Store GHCN-D CSV files here
│ └── Yelp JSON/ # Store Yelp JSON files here
├── create_tables.sql # SQL script to define the DW schema (tables, indexes)
├── run_etl.py # Python script for the ETL process
├── run_analysis.py # Python script to query the DW and perform analysis
├── yelp_weather.db # SQLite database file (Generated by setup steps)
└── README.md # This file

## Setup Requirements

1.  **Python:** Python 3.8 or higher recommended.
2.  **Python Libraries:** Install required packages using pip:
    ```bash
    pip install pandas sqlalchemy
    ```
3.  **SQLite:** The `sqlite3` command-line tool is needed to create the initial database schema. This is typically pre-installed on Linux/macOS and can be downloaded for Windows.
4.  **Data Placement:**
    *   Create a `data` directory in the same location as the scripts.
    *   Inside `data`, create `Yelp JSON` and `Climate Data` subdirectories.
    *   Place the provided Yelp JSON files into `data/Yelp JSON/`.
    *   Place the provided GHCN-D CSV files into `data/Climate Data/`.
    *   *(Alternatively, update the file path variables at the top of `run_etl.py` if you store data elsewhere).*

## Usage Instructions

**Follow these steps in order:**

1.  **Create Database Schema (Manual Step):**
    *   **Note:** While schema creation *could* potentially be handled directly within the Python ETL script, it has been separated into this required manual step using the `sqlite3` command-line tool. This approach was adopted during development to ensure consistent and reliable execution of the multi-statement SQL schema script (`create_tables.sql`) across different environments, as direct execution via the Python `sqlite3` library or SQLAlchemy sometimes presents challenges with complex initial scripts.
    *   Open your terminal or command prompt in the project directory.
    *   Run the following commands to create the SQLite database file (`yelp_weather.db`) and execute the schema definition script:
        ```bash
        # Create/Open the database file with the SQLite tool
        sqlite3 yelp_weather.db

        # Once inside the SQLite prompt (sqlite>), execute the schema script:
        sqlite> .read create_tables.sql

        # Exit the SQLite prompt
        sqlite> .exit
        ```
    *   *(Alternative method, might work depending on your system):*
        ```bash
        # sqlite3 yelp_weather.db < create_tables.sql
        ```
    *   This step creates the necessary tables (`dim_date`, `dim_restaurant`, `dim_user`, `fact_reviews`) and indexes. **It is essential to complete this step before proceeding.**

2.  **Run ETL Process:**
    *   Execute the `run_etl.py` script. This will read the raw data, perform transformations, and load the cleaned data into the `yelp_weather.db` database tables created in Step 1.
    ```bash
    python run_etl.py
    ```
    *   This may take some time depending on the data volume and your machine's performance. Monitor the console output for progress and any potential warnings/errors.

3.  **Run Analysis:**
    *   Once the ETL process is complete, execute the `run_analysis.py` script. This script connects to the populated `yelp_weather.db`, runs predefined SQL queries, and prints the analysis results to the console.
    ```bash
    python run_analysis.py
    ```

## Important: Data Limitation and Analysis Caveats

*   **Data Mismatch:** During development, it was discovered that the provided `yelp_academic_dataset_business.json` contained **insufficient business entries for Las Vegas, NV**.
*   **Adaptation:** To demonstrate the technical workflow, the ETL process (`run_etl.py`) was adapted to filter for and process businesses located in **Reno, NV** instead, as data for this city was present.
*   **Consequence:** However, the provided weather data (`Climate Data`) is specifically for **Las Vegas, NV**. This data was used as-is per the test requirements.
*   **Impact:** This creates a **fundamental geographical mismatch** between the business/review data (Reno) and the weather data (Las Vegas).

**Therefore, the analytical results generated by `run_analysis.py` regarding the relationship between weather patterns and Yelp ratings ARE NOT VALID OR ACTIONABLE REAL-WORLD INSIGHTS.** Any apparent correlations between Las Vegas weather and Reno reviews are likely spurious due to this mismatch.

**The primary value of this project lies in demonstrating the technical ability to:**
    1.  Design a suitable Data Warehouse schema.
    2.  Implement an ETL pipeline to process and load disparate data sources.
    3.  Query the resulting Data Warehouse for analysis, even if the underlying data used had significant limitations preventing valid conclusions.

## Data Warehouse Schema Overview

A Star Schema was implemented with the following tables stored in `yelp_weather.db`:

*   **`dim_date`:** Dimension table containing date attributes (year, month, day, weekday, weekend flag, etc.) and corresponding daily weather metrics (max/min temperature, precipitation) for Las Vegas. Serves as a combined Date and Weather dimension for simplicity in this context.
*   **`dim_restaurant`:** Dimension table storing details about restaurants (ID, name, categories, location, average stars from business data, etc.) - *Note: Contains Reno businesses due to data limitations.*
*   **`dim_user`:** Dimension table storing unique user IDs. Can be expanded with more user attributes if `user.json` is fully processed.
*   **`fact_reviews`:** Fact table containing individual review records. Each row links to the relevant date, restaurant, and user via foreign keys and includes the review rating as the primary measure.

## Analysis Performed (`run_analysis.py`)

## Summary of Analysis Output (Illustrative Only)

The `run_analysis.py` script executes queries against the populated data warehouse. Below is a summary of the output generated during a sample run.

**CRITICAL REMINDER:** As detailed in the "Data Limitation" section, the underlying data combines **Reno, NV business reviews** with **Las Vegas, NV weather data**. This geographical mismatch means the following observations **DO NOT represent valid real-world insights** about the effect of weather on restaurant ratings. They merely demonstrate the *types* of analysis the technical pipeline enables.

---

**1. Analysis: Impact of Precipitation**

*   **Observation:** Days flagged with precipitation (`had_precipitation = 1`) showed a slightly higher average rating (3.795) compared to days without (`had_precipitation = 0`, avg rating 3.736). The number of reviews was significantly higher on days flagged with precipitation.
*   **Interpretation Caveat:** This small, counter-intuitive difference and the volume disparity are likely artifacts of the mismatched datasets and cannot be considered evidence that Las Vegas rain improves Reno reviews.

**2. Analysis: Impact of Temperature**

*   **Observation:** Average ratings were relatively consistent (~3.76-3.80) across 'Very Cold' (<5 C), 'Cold' (5-15 C), 'Mild' (15-25 C), and 'Warm' (25-35 C) temperature ranges (based on Las Vegas max temps). A noticeable drop in average rating (3.478) was observed for the 'Hot' (>=35 C) category, however, this was based on a very small sample size of only 23 reviews.
*   **Interpretation Caveat:** The consistency across most bands and the drop in the 'Hot' band cannot be reliably interpreted due to the geographical mismatch. The low review count for the 'Hot' category makes its average highly susceptible to outliers and statistically unreliable.

**3. Analysis: Weekend vs. Weekday Precipitation Impact**

*   **Observation:** On both weekdays (`is_weekend = 0`) and weekends (`is_weekend = 1`), days flagged with precipitation showed slightly higher average ratings than days without. Weekend ratings appeared slightly lower overall than weekday ratings.
*   **Interpretation Caveat:** The pattern observed regarding precipitation remains invalid due to the data mismatch. Any potential real difference between weekday/weekend ratings cannot be reliably assessed without correct, geographically aligned weather data.

**Conclusion on Analysis Output:**

While the analysis script successfully runs and produces aggregated results, the critical mismatch between the location of the businesses/reviews (Reno) and the weather data (Las Vegas) renders any conclusions about weather's impact invalid. The primary takeaway is the successful execution of the technical analysis pipeline against the constructed data warehouse.